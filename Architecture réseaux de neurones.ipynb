{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation de l'architecture des réseaux de neurones\n",
    "\n",
    "*http://exo7.emath.fr/cours/livre-deepmath.pdf* \n",
    "\n",
    "## Chargement des modules et données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from sklearn import preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('market_data_pd.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Reference Security</th>\n",
       "      <th>Ticker_x</th>\n",
       "      <th>Bid Price</th>\n",
       "      <th>Ask Price</th>\n",
       "      <th>Mid Price</th>\n",
       "      <th>Issuer Name</th>\n",
       "      <th>Cpn</th>\n",
       "      <th>Maturity</th>\n",
       "      <th>Ticker_y</th>\n",
       "      <th>...</th>\n",
       "      <th>Tot Debt / Tot Capital</th>\n",
       "      <th>Tot Loans to Tot Assets</th>\n",
       "      <th>Tot Risk-Based Cap</th>\n",
       "      <th>Earnings Assets / Int Bear Liab</th>\n",
       "      <th>Total Expenses to Average Earning Assets</th>\n",
       "      <th>PD_1y</th>\n",
       "      <th>BCLASS Level 1</th>\n",
       "      <th>BCLASS Level 2</th>\n",
       "      <th>BCLASS Level 3</th>\n",
       "      <th>BCLASS Level 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AU053739 Corp</td>\n",
       "      <td>AABHFH</td>\n",
       "      <td>100.086</td>\n",
       "      <td>100.098</td>\n",
       "      <td>100.0920</td>\n",
       "      <td>Alandsbanken Abp</td>\n",
       "      <td>0.50</td>\n",
       "      <td>09/13/2021</td>\n",
       "      <td>AABHFH</td>\n",
       "      <td>...</td>\n",
       "      <td>87.2526</td>\n",
       "      <td>72.7382</td>\n",
       "      <td>275.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Financial Institutions</td>\n",
       "      <td>Banking</td>\n",
       "      <td>Banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BP432479 Corp</td>\n",
       "      <td>AAFFP</td>\n",
       "      <td>101.450</td>\n",
       "      <td>102.108</td>\n",
       "      <td>101.7790</td>\n",
       "      <td>Afflelou SAS</td>\n",
       "      <td>4.25</td>\n",
       "      <td>05/19/2026</td>\n",
       "      <td>AAFFP</td>\n",
       "      <td>...</td>\n",
       "      <td>77.8533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068537</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Retailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BP486833 Corp</td>\n",
       "      <td>AAFFP</td>\n",
       "      <td>101.375</td>\n",
       "      <td>102.375</td>\n",
       "      <td>101.8750</td>\n",
       "      <td>Afflelou SAS</td>\n",
       "      <td>8.00</td>\n",
       "      <td>05/19/2027</td>\n",
       "      <td>AAFFP</td>\n",
       "      <td>...</td>\n",
       "      <td>77.8533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119209</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Retailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EJ102177 Corp</td>\n",
       "      <td>AALLN</td>\n",
       "      <td>102.360</td>\n",
       "      <td>102.801</td>\n",
       "      <td>102.5805</td>\n",
       "      <td>Anglo American Capital PLC</td>\n",
       "      <td>3.50</td>\n",
       "      <td>03/28/2022</td>\n",
       "      <td>AALLN</td>\n",
       "      <td>...</td>\n",
       "      <td>80.4119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030968</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>Basic Industry</td>\n",
       "      <td>Metals and Mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>EK150567 Corp</td>\n",
       "      <td>AALLN</td>\n",
       "      <td>105.728</td>\n",
       "      <td>105.887</td>\n",
       "      <td>105.8075</td>\n",
       "      <td>Anglo American Capital PLC</td>\n",
       "      <td>3.25</td>\n",
       "      <td>04/03/2023</td>\n",
       "      <td>AALLN</td>\n",
       "      <td>...</td>\n",
       "      <td>80.4119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>Basic Industry</td>\n",
       "      <td>Metals and Mining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Reference Security Ticker_x  Bid Price  Ask Price  Mid Price  \\\n",
       "0           0      AU053739 Corp   AABHFH    100.086    100.098   100.0920   \n",
       "1           1      BP432479 Corp    AAFFP    101.450    102.108   101.7790   \n",
       "2           2      BP486833 Corp    AAFFP    101.375    102.375   101.8750   \n",
       "3           3      EJ102177 Corp    AALLN    102.360    102.801   102.5805   \n",
       "4           4      EK150567 Corp    AALLN    105.728    105.887   105.8075   \n",
       "\n",
       "                  Issuer Name   Cpn    Maturity Ticker_y  ...  \\\n",
       "0            Alandsbanken Abp  0.50  09/13/2021   AABHFH  ...   \n",
       "1                Afflelou SAS  4.25  05/19/2026    AAFFP  ...   \n",
       "2                Afflelou SAS  8.00  05/19/2027    AAFFP  ...   \n",
       "3  Anglo American Capital PLC  3.50  03/28/2022    AALLN  ...   \n",
       "4  Anglo American Capital PLC  3.25  04/03/2023    AALLN  ...   \n",
       "\n",
       "   Tot Debt / Tot Capital  Tot Loans to Tot Assets  Tot Risk-Based Cap  \\\n",
       "0                 87.2526                  72.7382               275.5   \n",
       "1                 77.8533                      NaN                 NaN   \n",
       "2                 77.8533                      NaN                 NaN   \n",
       "3                 80.4119                      NaN                 NaN   \n",
       "4                 80.4119                      NaN                 NaN   \n",
       "\n",
       "   Earnings Assets / Int Bear Liab  Total Expenses to Average Earning Assets  \\\n",
       "0                              NaN                                       NaN   \n",
       "1                              NaN                                       NaN   \n",
       "2                              NaN                                       NaN   \n",
       "3                              NaN                                       NaN   \n",
       "4                              NaN                                       NaN   \n",
       "\n",
       "      PD_1y  BCLASS Level 1          BCLASS Level 2     BCLASS Level 3  \\\n",
       "0  0.053266       Corporate  Financial Institutions            Banking   \n",
       "1  0.068537       Corporate              Industrial  Consumer Cyclical   \n",
       "2  0.119209       Corporate              Industrial  Consumer Cyclical   \n",
       "3  0.030968       Corporate              Industrial     Basic Industry   \n",
       "4  0.016911       Corporate              Industrial     Basic Industry   \n",
       "\n",
       "      BCLASS Level 4  \n",
       "0            Banking  \n",
       "1          Retailers  \n",
       "2          Retailers  \n",
       "3  Metals and Mining  \n",
       "4  Metals and Mining  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre les ratios financiers\n",
    "df1 = df[[\"Common Eqty / Tot Assets\",'Debt / Common Equity','BCLASS Level 3',\"PD_1y\"]]\n",
    "#df1.replace(np.nan, 0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna(how = 'any') \n",
    "df1.head()\n",
    "#on peut pas faire tourner l'algo avec des valeurs manquantes. Voir techniques pour les remplacer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = np.array(df1.drop(columns=['PD_1y']))\n",
    "y_full = np.array(df1['PD_1y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df1.drop(columns=['PD_1y']).columns)\n",
    "\n",
    "discrete_features = ['BCLASS Level 3']\n",
    "continuous_features = [s for s in features if not s in discrete_features]\n",
    "\n",
    "\n",
    "continuous_features_idx = [features.index(feat_name) for feat_name in continuous_features]\n",
    "discrete_features_idx = [features.index(feat_name) for feat_name in discrete_features]\n",
    "\n",
    "\n",
    "def traitement(X):\n",
    "    \n",
    "    ohe = preprocessing.OneHotEncoder(categories='auto',sparse=False)\n",
    "    \n",
    "    std_scaler = preprocessing.StandardScaler().fit(X[:,continuous_features_idx])\n",
    "    X_continuous_scaled = std_scaler.transform(X[:,continuous_features_idx])\n",
    "    \n",
    "    X_processed = np.hstack((ohe.fit_transform(X[:,discrete_features_idx]), X_continuous_scaled))\n",
    "    \n",
    "    return X_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = traitement(X_full)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_processed, y_full, test_size=0.20,\n",
    "                                                                    #stratify=y_full, # stratification\n",
    "                                                                    random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Préparation bases de train et de test \n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df1.drop(\"PD_1y\",axis=1),df1[\"PD_1y\"],test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables quanti : standardisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.columns[X_train.dtypes.apply(lambda c: np.issubdtype(c, np.number))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisation des données \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(X_train[num_cols])\n",
    "    \n",
    "\n",
    "x_train = X_train\n",
    "x_train[num_cols] = scaler.transform(X_train[num_cols])\n",
    "x_train = pd.DataFrame(x_train, index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "x_test = X_test\n",
    "x_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "x_test = pd.DataFrame(x_test, index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['Debt / Common Equity'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables quali : binariser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARISER\n",
    "x_train = pd.get_dummies(x_train)\n",
    "x_test = pd.get_dummies(x_test)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseaux de neurones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESEAUX DE NEURONES \n",
    "#http://eric.univ-lyon2.fr/~ricco/tanagra/fichiers/fr_Tanagra_Packages_Python_for_Deep_Learning.pdf\n",
    "\n",
    "#Explications très bien dans ce document : \n",
    "\n",
    "#http://exo7.emath.fr/cours/livre-deepmath.pdf \n",
    "\n",
    "#très bon document (parties Python, keras avec les codes et explications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele = Sequential()\n",
    "modele.add(Dense(units=7,input_dim=23,activation=\"sigmoid\")) #6 is good\n",
    "modele.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "#modele.add(Dropout(0.3))\n",
    "learning_rate = 0.10\n",
    "\n",
    "sgd = SGD(learning_rate)\n",
    "\n",
    "#dim première couche = nombre de variables du df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai pris la fonction sigmoïde car elle est continue et à valeurs dans [0,1] (comme les probabilités de défaut). Régression logit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.compile(loss='mean_squared_error',optimizer=sgd,metrics=[tf.keras.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modele.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modele.fit(X_train, y_train,         # Train the model using the training set...\n",
    "          batch_size=10, epochs=9,\n",
    "          verbose=1, validation_split=0.35,steps_per_epoch=15)           # ...holding out 40% of the data for validation\n",
    "\n",
    "# --------------------------------------\n",
    "# Evaluation\n",
    "# --------------------------------------\n",
    "#for loss_name, loss_value in list(zip(modele.metrics_names, modele.evaluate(x_test, y_test, verbose=1))):\n",
    " #   print('The final {} on the TEST set is: {:.2f}.'.format(loss_name, loss_value)) # Evaluate the trained model on the test set!\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------\n",
    "# Loss functions evolution\n",
    "# --------------------------------------\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Résultats \n",
    "\n",
    "resultat = modele.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Valeur de l'erreur sur les données de test (loss):\", resultat[0])\n",
    "print('Précision sur les données de test (MSE):', resultat[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecart_relatif(row) : \n",
    "    théo = row['Théorique']\n",
    "    préd = row['Prédiction']\n",
    "    return abs(théo - préd) / théo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(data= modele.predict(X_test) ,columns=['Prédiction'])\n",
    "théorique = pd.DataFrame(data= y_test ,columns=['Théorique'])\n",
    "prediction, théorique = prediction.reset_index() , théorique.reset_index()\n",
    "\n",
    "results = pd.merge(théorique, prediction, on = 'index').drop(columns=['index'])\n",
    "results[\"Ecart_relatif\"] = results.apply(ecart_relatif,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Ecart_relatif\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"L'écart relatif moyen est de \" + str(results[\"Ecart_relatif\"].mean() * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Ecart_relatif\"] = results.apply(ecart_relatif,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.scatter(\"Théorique\",\"Prédiction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.sort_values('PD_1y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df2.iterrows():\n",
    "    print('+==========')\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([410.513,79.0061,80.4119]).reshape(-1,1) #ligne 1 et 2\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(arr)\n",
    "\n",
    "x = scaler.transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-0.079178,-0.424929,1.104960]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.predict(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
